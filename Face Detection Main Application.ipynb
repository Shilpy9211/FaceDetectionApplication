{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with created Face Recognizer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-8edfa1377834>:19: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if faces == ():\n",
      "<ipython-input-11-8edfa1377834>:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if rect == []:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 35.17734874490337)\n",
      "(1, 34.993490435328205)\n",
      "(1, 33.67182479667612)\n",
      "(1, 34.83254063471713)\n",
      "(1, 35.10046247925729)\n",
      "(1, 34.66365704835026)\n",
      "(1, 35.142841464676366)\n",
      "(1, 33.61438959594726)\n",
      "(1, 34.632781488185934)\n",
      "(1, 32.96099271743419)\n",
      "(1, 35.99520552527222)\n",
      "(1, 33.7248158747691)\n",
      "(1, 34.4151109202124)\n",
      "(1, 33.94347541648792)\n",
      "(1, 33.85324328826234)\n",
      "(1, 33.438107146292175)\n",
      "(1, 32.537834520392884)\n",
      "(1, 33.90020996367024)\n",
      "(1, 32.89841120612667)\n",
      "(1, 34.29774383159439)\n",
      "(1, 35.497736112469255)\n",
      "(1, 34.65280633053335)\n",
      "(1, 34.79856909203667)\n",
      "(1, 96.55045775961848)\n",
      "(1, 34.96432675004849)\n",
      "(1, 35.07262574035144)\n",
      "(1, 33.84693297439886)\n",
      "(1, 34.64018761105492)\n",
      "(1, 34.65464097462062)\n",
      "(1, 35.66350457716928)\n",
      "(1, 34.9529152112286)\n",
      "(1, 38.88335216480139)\n",
      "(1, 37.11534819239546)\n",
      "(1, 47.610316617448476)\n",
      "(1, 45.69498860928154)\n",
      "(1, 47.288892946520996)\n",
      "(1, 46.36353023009575)\n",
      "(1, 47.643511165188414)\n",
      "(1, 44.64415926245857)\n",
      "(1, 45.41133452837343)\n",
      "(1, 47.34922071976509)\n",
      "(1, 46.92731948051069)\n",
      "(1, 43.2129191044543)\n",
      "(1, 45.99669575295962)\n",
      "(1, 44.883451047653196)\n",
      "(1, 45.038138279635945)\n",
      "(1, 44.561325377529364)\n",
      "(1, 44.04350421091339)\n",
      "(1, 44.32919030393615)\n",
      "(1, 45.243801816311496)\n",
      "(1, 44.68137363383346)\n",
      "(1, 44.66843043024425)\n",
      "(1, 46.256016395664325)\n",
      "(1, 44.26802673045046)\n",
      "(1, 45.418294504513014)\n",
      "(1, 42.67294709549278)\n",
      "(1, 40.43555980955605)\n",
      "(1, 41.98649179041695)\n",
      "(1, 41.3558447957363)\n",
      "(1, 40.556156401718816)\n",
      "(1, 40.21990284025299)\n",
      "(1, 39.092238658625924)\n",
      "(1, 40.537852253841294)\n",
      "(1, 39.12883804885717)\n",
      "(1, 37.495074255893535)\n",
      "(1, 40.1030378744635)\n",
      "(1, 39.355467301193386)\n",
      "(1, 36.47471253321393)\n",
      "(1, 36.68380038252299)\n",
      "(1, 36.389921012971094)\n",
      "(1, 37.307982388580015)\n",
      "(1, 38.72542308937564)\n",
      "(1, 40.21583689003965)\n",
      "(1, 38.39439284302438)\n",
      "(1, 37.32022431769647)\n",
      "(1, 38.7384869049611)\n",
      "(1, 97.10643215196556)\n",
      "(1, 40.331464416388286)\n",
      "(1, 38.409285471279674)\n",
      "(1, 41.05486172991924)\n",
      "(1, 39.16248755194487)\n",
      "(1, 38.685841127232784)\n",
      "(1, 37.14779272426623)\n",
      "(1, 37.83073334475738)\n",
      "(1, 38.07076452303278)\n",
      "(1, 38.17418070669401)\n",
      "(1, 38.9178611131086)\n",
      "(1, 42.047648235084296)\n",
      "(1, 40.96380059928078)\n",
      "(1, 41.04200102385008)\n",
      "(1, 41.09689860602733)\n",
      "(1, 97.47804694902752)\n",
      "(1, 42.23573384342673)\n",
      "(1, 39.6246248277995)\n",
      "(1, 40.8858499310336)\n",
      "(1, 40.1910844181198)\n",
      "(1, 101.16317068602106)\n",
      "(1, 39.86795762512)\n",
      "(1, 39.94097168184137)\n",
      "(1, 42.37412614342258)\n",
      "(1, 42.11045556820672)\n",
      "(1, 41.376471573067775)\n",
      "(1, 39.620748537365955)\n",
      "(1, 41.5842853781879)\n",
      "(1, 101.7700582884888)\n",
      "(1, 40.680110721296145)\n",
      "(1, 40.206843983085655)\n",
      "(1, 40.84805276451655)\n",
      "(1, 39.76223688407658)\n",
      "(1, 40.014089723559565)\n",
      "(1, 40.59919583303898)\n",
      "(1, 39.700070660233685)\n",
      "(1, 95.26470407841329)\n",
      "(1, 40.026433970880355)\n",
      "(1, 95.21306526897314)\n",
      "(1, 36.7470695580158)\n",
      "(1, 37.19170185088285)\n",
      "(1, 39.952143822557375)\n",
      "(1, 94.1164235204062)\n",
      "(1, 36.76429559581741)\n",
      "(1, 36.81810377170329)\n",
      "(1, 38.348216980330406)\n",
      "(1, 38.36649423302101)\n",
      "(1, 36.06620584718706)\n",
      "(1, 40.890801552674226)\n",
      "(1, 37.77783466821409)\n",
      "(1, 39.517061016188315)\n",
      "(1, 36.24283788299821)\n",
      "(1, 41.01868266402791)\n",
      "(1, 37.15785105783829)\n",
      "(1, 37.45630654902613)\n",
      "(1, 36.91136166986101)\n",
      "(1, 36.989091921176566)\n",
      "(1, 39.23727654435316)\n",
      "(1, 39.473077570753894)\n",
      "(1, 38.66942729765109)\n",
      "(1, 39.14239370831451)\n",
      "(1, 40.1753444158825)\n",
      "(1, 36.24883505380961)\n",
      "(1, 39.912749608403296)\n",
      "(1, 38.45717597844519)\n",
      "(1, 37.66709162182463)\n",
      "(1, 40.30588746062805)\n",
      "(1, 39.22813911490768)\n",
      "(1, 40.77222134876105)\n",
      "(1, 37.61087586162043)\n",
      "(1, 37.82435079378669)\n",
      "(1, 39.27429082619684)\n",
      "(1, 40.692380709593245)\n",
      "(1, 99.19760532862806)\n",
      "(1, 37.02974409870468)\n",
      "(1, 39.24953403863219)\n",
      "(1, 40.221634053149565)\n",
      "(1, 40.11655675228502)\n",
      "(1, 38.39467102552297)\n",
      "(1, 39.78612034371592)\n",
      "(1, 39.16380163623586)\n",
      "(1, 37.5812915597217)\n",
      "(1, 38.40271628227375)\n",
      "(1, 40.099396341926656)\n",
      "(1, 39.97027219187243)\n",
      "(1, 38.107174724610914)\n",
      "(1, 38.27188872683429)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "subjects = [\"\", \"Shilpy\", \"Vimal Sir\"]\n",
    "def draw_rectangle(img, rect):\n",
    "    if rect == []:\n",
    "        return img\n",
    "    else:\n",
    "        (x, y, w, h) = rect\n",
    "        return cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "    \n",
    "def draw_text(img, text):\n",
    "    if img is not None:\n",
    "        cv2.putText(img, text, (200, 100), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 0, 255), 5)\n",
    "\n",
    "def face_extractor(img ):\n",
    "    \n",
    "    faces = face_classifier.detectMultiScale(img, 1.4, 2)\n",
    "    if faces == ():\n",
    "        return img, []\n",
    "    \n",
    "    else:\n",
    "        for (x,y,w,h) in faces:\n",
    "            img = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "            detected_face = img[y:y+h, x:x+w]\n",
    "            detected_face = cv2.resize(detected_face, (200, 200))\n",
    "            return detected_face, faces[0]\n",
    "        \n",
    "cap = cv2.VideoCapture(0)\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "face_recognizer = cv2.face_LBPHFaceRecognizer.create() \n",
    "face_recognizer.read(\"face_recognizer.h5\")\n",
    "while True:\n",
    "   \n",
    "        ret, frame = cap.read()\n",
    "        face, rect = face_extractor(frame)\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)      \n",
    "        label = face_recognizer.predict(face)\n",
    "        label_text = subjects[label[0]]\n",
    "        print(label)\n",
    "        x = draw_rectangle(frame, rect )\n",
    "        #draw_text(frame, label_text, rect[0][0], rect[0][1]-5)\n",
    "        draw_text(x, label_text)\n",
    "        cv2.imshow(\"hii\", frame)\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "        \n",
    "   \n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "import os\n",
    "import getpass\n",
    "import imghdr         \n",
    "from email.message import EmailMessage         #for setting and querying header fields, for accessing message bodies, for creating or modifying structured messages\n",
    "\n",
    "def send_email():\n",
    "    message = EmailMessage()\n",
    "    \n",
    "    Sender_Mail = os.environ.get('MY_EMAIL')\n",
    "    Sender_Password = os.environ.get(\"SenderPassword\")\n",
    "    Receiver_mail = os.environ.get(\"Recvmail\")\n",
    "  \n",
    "    \n",
    "    print(\"Sending mail....\")\n",
    "    \n",
    "    message['subject'] = \"Anonymous person found in working area\"\n",
    "    message['from'] = Sender_Mail\n",
    "    message['to'] = Receiver_mail\n",
    "    message.set_content(\"Welcome to Face recognition app\" )\n",
    "    \n",
    "   # converting image into byte format, as we need byte data to dend over network\n",
    "    with open(\"./image/Crop.jpg\" , \"rb\") as attach_file:\n",
    "        image_name = attach_file.name\n",
    "        image_type = imghdr.what(attach_file.name)\n",
    "        image_data = attach_file.read()\n",
    "    \n",
    "    #specifying the content of mail to be sent.\n",
    "    message.add_attachment(image_data , maintype = \"image\", subtype = image_type , filename = \"FaceLock.png\")\n",
    "    \n",
    "    #to connect with gmail server\n",
    "    with smtplib.SMTP_SSL(\"smtp.gmail.com\",465) as smtp:\n",
    "        smtp.login(Sender_Mail,Sender_Password)\n",
    "        smtp.send_message(message)\n",
    "        \n",
    "    print(\"Mail Sent sucessfully\")\n",
    "    \n",
    "#send_email()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Whatsapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywhatkit \n",
    "import os\n",
    "from datetime import datetime                        #datetime module to get current time\n",
    "\n",
    "def do_whatsapp():\n",
    "    now = datetime.now()           # Get current time\n",
    "    hr = int(now.strftime(\"%H\"))   # Current Hour\n",
    "    min = int( now.strftime(\"%M\"))  # Current mint\n",
    "    \n",
    "    ContactNo =os.environ.get('contactNo.')\n",
    "\n",
    "    \n",
    "    pywhatkit.sendwhatmsg(ContactNo,\"Hi Shilpy ,Someone entered into your working area\", hr,min+1 ,wait_time=5)\n",
    "    #pywhatkit.sendwhatmsg(ContactNo,r\"./image/Crop.jpg\" , hr,min+1 ,wait_time=20)\n",
    "\n",
    "do_whatsapp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Terraform Infrastructure launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terraform():\n",
    "    print(\"Installing required plugins\")\n",
    "    stream = os.popen('terraform init')\n",
    "    output = stream.readlines()\n",
    "        #output\n",
    "    for line in output:\n",
    "        print(line.strip())\n",
    "            \n",
    "        print(\"Deploying infrastructure\")\n",
    "        stream = os.popen('terraform apply')\n",
    "        output = stream.readlines()\n",
    "        #output\n",
    "        for line in output:\n",
    "            print(line.strip())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for AWS EC2 launch , Volume create & Attach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "def launch_instance():\n",
    "    ec2_client = boto3.client(\"ec2\", region_name=\"us-west-2\")\n",
    "    #key_pair = ec2_client.create_key_pair(KeyName=\"ec2-key-pair\")\n",
    "    #private_key = key_pair[\"KeyMaterial\"]\n",
    "    instances = ec2_client.run_instances(\n",
    "        ImageId=\"ami-0800fc0fa715fdcfe\",\n",
    "        MinCount=1,\n",
    "        MaxCount=1,\n",
    "        InstanceType=\"t2.micro\",\n",
    "        KeyName=\"ec2-key-pair\"\n",
    "    )\n",
    "    #print(instances)\n",
    "    return (instances[\"Instances\"][0][\"InstanceId\"]), (instances[\"Instances\"][0][\"Placement\"][\"AvailabilityZone\"])\n",
    "#instances() returns a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_attach_volume(instanceId, az):\n",
    "    \n",
    "    client = boto3.client(\"ec2\", region_name=\"us-west-2\")\n",
    "    response = client.create_volume(\n",
    "        AvailabilityZone= az,\n",
    "        Size=5,\n",
    "        VolumeType=\"gp2\",\n",
    "    )\n",
    "    volumeId = response[\"VolumeId\"]\n",
    "    \n",
    "    response = client.attach_volume(\n",
    "        Device='/dev/sdf',\n",
    "        InstanceId = instanceId,\n",
    "        VolumeId = volumeId,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function when Shilpy's face is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.youtube.com/watch?v=fK2sZSsticI'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pywhatkit as kit\n",
    "import os\n",
    "def good_morning():\n",
    "    kit.playonyt(\"https://www.youtube.com/watch?v=fK2sZSsticI\")\n",
    "    os.system(\"code .\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Face detection Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def condition():\n",
    "    if Shilpy == 100:\n",
    "        tf = cv2.imread(\"images.jpg\")\n",
    "        cv2.putText(tf, \"Access\", (45, 50) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(tf, \"Granted\", (45, 100) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow(\"permission\" , tf)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Playing songs for you....\")\n",
    "        print(\"Opening VS code for you...\")\n",
    "        good_morning()\n",
    "        print(\"Good Morning Darling!!\")\n",
    "        \n",
    "    elif Sir == 25:\n",
    "        aws = cv2.imread(\"capture-5.png\")\n",
    "        cv2.putText(aws, \"Permitted\", (50, 100) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow(\"Permission\", aws)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Launching EC2 Instance...\")\n",
    "        #instanceId, availabilityZone = launch_instance()\n",
    "        print(\"Creating Volume...\")\n",
    "        time.sleep(30)\n",
    "        print(\"Attaching Volume...\")\n",
    "        #create_and_attach_volume(instanceId, availabilityZone)\n",
    "        print(\"EC2 launched , volume created and attached successfully\")\n",
    "        \n",
    "        \n",
    "    elif Anon == 150:\n",
    "        lock = cv2.imread(\"lock.jpg\")\n",
    "        cv2.putText(lock, \"Access\", (45, 50) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(lock, \"Denied\", (45, 100) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow(\"lock\" , lock)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.imshow(\"lock\" , image)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()\n",
    "        face_anon = face_classifier.detectMultiScale(image, 1.4, 6)\n",
    "        for x,y,w,h in face_anon:\n",
    "            cimg1 = image[y:y+h, x:x+w,  : ]\n",
    "            cv2.imwrite(\"./image/Crop.jpg\",cimg1)  \n",
    "        print(\"Sending Mail...\")\n",
    "        #send_email()\n",
    "        print(\"EMail sent sucessfully\")\n",
    "        print(\"Sending Whatsapp message...\")\n",
    "        #do_whatsapp()\n",
    "        print(\"WhatsApp Done sucessfully\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If Shilpy ---> Aws Service launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elif Vimal Sir ---> Terraform Infrastructure launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Else ---> Email & Whatsapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-68-0efb73ec37b0>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aws ec2 will be launched and volume will be attached\n",
      "EC2 launched , volume created and attached successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "Face_recognizer  = cv2.face_LBPHFaceRecognizer.create() \n",
    "Face_recognizer.read(\"face_recognizer.h5\")\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img ):\n",
    "    \n",
    "    faces = face_classifier.detectMultiScale(img, 1.4,3)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    else:\n",
    "        for (x,y,w,h) in faces:\n",
    "            img = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "            detected_face = img[y:y+h, x:x+w]\n",
    "            detected_face = cv2.resize(detected_face, (200, 200))\n",
    "            return img, detected_face\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "Shilpy = 0\n",
    "Anon = 0\n",
    "Sir = 0\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    image, detected_face = face_detector(frame)\n",
    "\n",
    "    try:\n",
    "        face = cv2.cvtColor(detected_face, cv2.COLOR_BGR2GRAY)        \n",
    "        model_output = Face_recognizer.predict(face)\n",
    "        \n",
    "        if model_output[1] < 500:\n",
    "            confidence = int( 100 * (1 - (model_output[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if model_output[0] == 2 and confidence >= 70:\n",
    "            cv2.putText(image, \"Pranam :-) Vimal Sir\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            Sir += 1\n",
    "            \n",
    "        #elif confidence < 90:\n",
    "        elif model_output[0]== 1 and confidence >=90:\n",
    "            cv2.putText(image, \"Hello Shilpy\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            Shilpy += 1\n",
    "            \n",
    "        else :\n",
    "            cv2.putText(image, \"Anonymous face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            Anon += 1\n",
    "            \n",
    "                    \n",
    "        if Shilpy == 100:\n",
    "            print(\"Aws ec2 will be launched and volume will be attached\") \n",
    "            break\n",
    "            \n",
    "        elif Sir == 25:\n",
    "            print(\"Your Terraform infrastructure will be deployed\")\n",
    "            break\n",
    "            \n",
    "        elif Anon == 150:\n",
    "            print(\"Anonymous person found\")            \n",
    "            break\n",
    "                    \n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13: \n",
    "        break\n",
    "        \n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "condition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(int('014'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
